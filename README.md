
README.md:

# ğŸ¥ Diabetes-Klassifikation mit SHAP-Analyse  

ğŸ“Š **Maschinelles Lernen zur Vorhersage von Diabetes mit XGBoost & Explainable AI (SHAP)**  

---

## ğŸ”¹ **Projektbeschreibung**  
Dieses Projekt nutzt **Machine Learning (XGBoost)**, um vorherzusagen, ob eine Person an Diabetes erkrankt ist.  
Mit **SHAP (SHapley Additive Explanations)** analysieren wir die Bedeutung einzelner Features und verstehen, wie unser Modell Entscheidungen trifft.  

---

## ğŸ”¹ **Daten**  
ğŸ“‚ **Datensatz:** [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/nancyalaswad90/review)  

**Spalten im Datensatz:**  
- `Glucose`: Blutzucker-Wert  
- `BMI`: Body Mass Index  
- `Age`: Alter der Person  
- `Pregnancies`, `BloodPressure`, `SkinThickness` u.a.  

---

## ğŸ”¹ **Verwendete Technologien**  
ğŸ **Python** (pandas, numpy, matplotlib)  
ğŸ¤– **Machine Learning**: XGBoost  
ğŸ¯ **Explainable AI**: SHAP  
ğŸ“ˆ **Datenvisualisierung**: Matplotlib, Seaborn  

---

## ğŸ† Modellvergleich: XGBoost vs. Random Forest vs. Logistische Regression

| Modell                     | Accuracy| Precision |   Recall   | F1-Score|
|----------------------------|---------|-----------|------------|---------|
| **XGBoost**                | 0.6039  | 0.4706    | **0.8727** | 0.6115  |
| **Random Forest**          | 0.7208  | 0.6071    | 0.6182     | 0.6126  |
| **Logi. Regression**       |**0.7532**|**0.6491**| 0.6727     |**0.6607**|

### Fazit
- **XGBoost hat den hÃ¶chsten Recall** (87,3%) â†’ Bestes (und dann auch gewÃ¤hltes) Modell, wenn mÃ¶glichst viele Diabetes-FÃ¤lle erkannt werden sollen.  
- **Logistische Regression hat die hÃ¶chste Accuracy (75,3%)** â†’ Bestes Modell, wenn Balance aus Precision & Recall gewÃ¼nscht ist.  
- **Random Forest liegt in der Mitte** â†’ Kann evtl. mit Feature Engineering verbessert werden.  
---
## â³ ARIMA-Zeitreihenanalyse fÃ¼r Glucose-Level

Das ARIMA(5,1,0)-Modell wurde trainiert, um den Glucose-Level Ã¼ber die Zeit zu modellieren.

**Modellstatistiken:**
- **AIC = 7614, BIC = 7642** â†’ Niedrigere Werte sind besser.
- **Alle AR-Koeffizienten sind signifikant** (p-Wert < 0.05).
- **Kurtosis = 3.38, Skew = 0.20** â†’ Fast normalverteilte Residuen.
- **Ljung-Box-Test (`Prob(Q) = 0.58`)** â†’ Kein Hinweis auf starke Autokorrelation.

### ğŸ“Œ Interpretation:
- **Das Modell kann fÃ¼r Glucose-Vorhersagen genutzt werden.**
- **Es zeigt eine autoregressive Struktur (Glucose-Level hÃ¤ngt von vorherigen Werten ab).**
  
---

## ğŸ”¹ **Feature Importance Analyse mit SHAP**  
### ğŸ“Š **Wichtigste Features laut SHAP**  
Hier eine SHAP Summary-Analyse, die zeigt, welche Features den grÃ¶ÃŸten Einfluss auf die Diabetes-Vorhersage haben:  

- **Glucose ist der wichtigste Faktor fÃ¼r eine Diabetes-Diagnose**  
- **BMI & Alter haben ebenfalls einen starken Einfluss**  
- **Andere Faktoren (SkinThickness, BloodPressure) haben geringere Auswirkungen**  
![Figure_1](https://github.com/user-attachments/assets/fb4df2e0-9850-4e17-b586-d63661ef5c96)

---

## **SHAP-AbhÃ¤ngigkeitsanalysen**  
### ğŸ”¹ **Glucose vs. Diabetes-Risiko**  
- Je hÃ¶her der **Glucose-Wert**, desto grÃ¶ÃŸer die Wahrscheinlichkeit einer Diabetes-Erkrankung  
- Der Effekt ist **linear** (hÃ¶here Werte = hÃ¶heres Risiko)  

![Figure_2](https://github.com/user-attachments/assets/3fe9f36b-0631-493d-a4c3-fa08ea2084b5)
### ğŸ”¹ **BMI vs. Diabetes-Risiko**  
- Ein **BMI Ã¼ber 30** erhÃ¶ht das Diabetes-Risiko sprunghaft  
- Ã„ltere Personen (rote Punkte) sind stÃ¤rker betroffen  
![Figure_3](https://github.com/user-attachments/assets/4ee3611b-b677-4ef2-b23a-7ab2e414b8e5)



---




